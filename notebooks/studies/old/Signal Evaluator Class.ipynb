{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b88add6-d833-4d91-84e3-ad5d7b910379",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from great_tables import GT, md, html\n",
    "# Assuming asset_returns, df_rebalanced, and price_changes are already defined\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "def create_portfolio_holdings_fast(df_signal):\n",
    "    # Convert to numpy array for faster operations\n",
    "    signal_array = df_signal.values\n",
    "\n",
    "    # Create the holdings array\n",
    "    holdings_array = np.zeros_like(signal_array)\n",
    "\n",
    "    # Set short positions (-1) where signal <= 10\n",
    "    holdings_array[signal_array <= 10] = -1\n",
    "\n",
    "    # Set long positions (1) where signal >= 90\n",
    "    holdings_array[signal_array >= 90] = 1\n",
    "\n",
    "    # Set NaNs where signal is NaN\n",
    "    holdings_array[np.isnan(signal_array)] = np.nan\n",
    "\n",
    "    # Convert back to DataFrame\n",
    "    df_holdings = pd.DataFrame(holdings_array, index=df_signal.index, columns=df_signal.columns)\n",
    "\n",
    "    return df_holdings\n",
    "\n",
    "\n",
    "def evaluator_construct(df_signal, df_prices):\n",
    "    # Create the portfolio holdings DataFrame\n",
    "    df_holdings = create_portfolio_holdings_fast(df_signal)\n",
    "    \n",
    "    # Replace NaNs with 2 (our temporary placeholder)\n",
    "    df_temp = df_holdings.fillna(2)\n",
    "    \n",
    "    # Create a 4-weekly rebalancing mask\n",
    "    rebalance_mask = pd.Series(False, index=df_temp.index)\n",
    "    rebalance_mask.iloc[0] = True  # Always include the first row\n",
    "    rebalance_mask.iloc[4::4] = True  # Then every 4th row\n",
    "    \n",
    "    # Apply the rebalancing mask\n",
    "    df_balance = df_temp.where(rebalance_mask, np.nan)\n",
    "    \n",
    "    # Forward fill\n",
    "    df_balance = df_balance.ffill()\n",
    "    \n",
    "    # Replace 2 with NaN to restore original NaN structure\n",
    "    df_balance = df_balance.replace(2, np.nan)\n",
    "    \n",
    "    df_balance = df_balance.replace(0, np.nan)\n",
    "    \n",
    "    # Assuming df_rebalanced and df_prices are already defined\n",
    "    \n",
    "    # Calculate percentage changes in prices\n",
    "    df_returns = df_prices.pct_change(fill_method=None)\n",
    "    \n",
    "    df_returns = df_returns.clip(upper=3)\n",
    "    \n",
    "    # Calculate returns for each asset based on holdings\n",
    "    asset_returns = df_balance * df_returns\n",
    "    \n",
    "    \n",
    "    # Calculate portfolio returns (sum across all assets for each date)\n",
    "    portfolio_returns = asset_returns.mean(axis=1)\n",
    "    \n",
    "    # Calculate cumulative returns\n",
    "    cumulative_returns = (1 + portfolio_returns).cumprod()\n",
    "    \n",
    "    ## 4 WEEKLY BASED RESAMPLING\n",
    "    \n",
    "    # Assuming df_returns is your DataFrame with weekly returns\n",
    "    # and rebalance_mask is your Series with the rebalancing mask\n",
    "    \n",
    "    # Create a custom resampler\n",
    "    def custom_resampler(x):\n",
    "        return x.sum()\n",
    "    # Ensure the index of df_returns is datetime\n",
    "    df_returns.index = pd.to_datetime(df_returns.index)\n",
    "    # Create a date range index for resampling, explicitly using Friday end dates\n",
    "    date_range = pd.date_range(start=df_returns.index.min(), end=df_returns.index.max(), freq='W-FRI')\n",
    "    # Reindex df_returns to ensure all Friday-ending weeks are present\n",
    "    df_returns_full = df_returns.reindex(date_range)\n",
    "    # Reindex rebalance_mask to match the Friday-ending weeks\n",
    "    rebalance_mask_full = rebalance_mask.reindex(date_range)\n",
    "    # Create a Series with incrementing group numbers\n",
    "    group_numbers = (rebalance_mask_full.cumsum() - 1).ffill()\n",
    "    # Group by the incremented numbers and apply the custom resampler\n",
    "    resampled_returns = df_returns_full.groupby(group_numbers).apply(custom_resampler)\n",
    "    # The resulting resampled_returns will contain the 4-week returns\n",
    "    resampled_returns.index = rebalance_mask[rebalance_mask==True].index\n",
    "    \n",
    "    asset_returns = df_balance * df_returns\n",
    "    \n",
    "    return df_balance,  df_returns, asset_returns, portfolio_returns, cumulative_returns,  resampled_returns, rebalance_mask\n",
    "\n",
    "\n",
    "\n",
    "def calculate_stats(returns, positions):\n",
    "    trades = returns * positions\n",
    "    \n",
    "    # print(f\"Shape of trades: {trades.shape}\")\n",
    "    # print(f\"Number of non-NaN trades: {trades.notna().sum().sum()}\")\n",
    "    \n",
    "    # Instead of dropping NaN, we'll use notna() to filter\n",
    "    # valid_trades = trades[trades.notna()]\n",
    "    # valid_positions = positions[positions.notna()]\n",
    "    \n",
    "    total_trades = ((positions != 0) & positions.notna()).sum().sum()\n",
    "    profitable_trades = ((trades > 0) & trades.notna()).sum().sum()\n",
    "    losing_trades = ((trades < 0) & trades.notna()).sum().sum()\n",
    "    # even_trades = ((trades == 0) & trades.notna()).sum().sum()\n",
    "    \n",
    "    # print(f\"Total trades: {total_trades}\")\n",
    "    # print(f\"Profitable trades: {profitable_trades}\")\n",
    "    # print(f\"Losing trades: {losing_trades}\")\n",
    "    # print(f\"Even trades: {even_trades}\")\n",
    "    \n",
    "    total_profit = trades.sum().sum()\n",
    "    gross_profit = trades[trades > 0].sum().sum()\n",
    "    gross_loss = trades[trades < 0].sum().sum()\n",
    "    \n",
    "    avg_trade_net_profit = total_profit / total_trades if total_trades > 0 else 0\n",
    "    avg_winning_trade = gross_profit / profitable_trades if profitable_trades > 0 else 0\n",
    "    avg_losing_trade = gross_loss / losing_trades if losing_trades > 0 else 0\n",
    "    \n",
    "    largest_winning_trade = trades.max().max() if not trades.empty else np.nan\n",
    "    largest_losing_trade = trades.min().min() if not trades.empty else np.nan\n",
    "\n",
    "    return {\n",
    "        'Total number of round_trips': int(total_trades),\n",
    "        'Percent profitable': profitable_trades / total_trades if total_trades > 0 else 0,\n",
    "        'Winning round_trips': int(profitable_trades),\n",
    "        'Losing round_trips': int(losing_trades),\n",
    "        # 'Even round_trips': int(even_trades),\n",
    "        'Total profit': total_profit,\n",
    "        'Gross profit': gross_profit,\n",
    "        'Gross loss': gross_loss,\n",
    "        'Profit factor': abs(gross_profit / gross_loss) if gross_loss != 0 else np.inf,\n",
    "        'Avg. trade net profit': avg_trade_net_profit,\n",
    "        'Avg. winning trade': avg_winning_trade,\n",
    "        'Avg. losing trade': avg_losing_trade,\n",
    "        'Ratio Avg. Win:Avg. Loss': abs(avg_winning_trade / avg_losing_trade) if avg_losing_trade != 0 else np.inf,\n",
    "        'Largest winning trade': largest_winning_trade,\n",
    "        'Largest losing trade': largest_losing_trade\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_stats(stats):\n",
    "    dollar_fields = ['Total profit', 'Gross profit', 'Gross loss', 'Avg. trade net profit', \n",
    "                     'Avg. winning trade', 'Avg. losing trade', 'Largest winning trade', 'Largest losing trade']\n",
    "    integer_fields = ['Total number of round_trips', 'Winning round_trips', 'Losing round_trips']\n",
    "    \n",
    "    for key, value in stats.items():\n",
    "        if key in integer_fields:\n",
    "            stats[key] = int(value)\n",
    "        elif key == 'Percent profitable':\n",
    "            stats[key] = f\"{value:.2%}\"\n",
    "        elif key in dollar_fields:\n",
    "            stats[key] = f\"${value:.2f}\"\n",
    "        elif isinstance(value, (int, float)):\n",
    "            stats[key] = f\"{value:.2f}\"\n",
    "    return stats\n",
    "\n",
    "\n",
    "def statistics(resampled_returns, df_balance):\n",
    "    price_changes, df_rebalanced = resampled_returns, df_balance\n",
    "    \n",
    "    # Calculate stats for all trades, short trades, and long trades\n",
    "    all_trades_stats = preprocess_stats(calculate_stats(price_changes, df_rebalanced))\n",
    "    short_trades_stats = preprocess_stats(calculate_stats(price_changes, df_rebalanced.where(df_rebalanced < 0, 0)))\n",
    "    long_trades_stats = preprocess_stats(calculate_stats(price_changes, df_rebalanced.where(df_rebalanced > 0, 0)))\n",
    "    \n",
    "    # Create summary stats table\n",
    "    summary_stats = pd.DataFrame({\n",
    "        'All trades': all_trades_stats,\n",
    "        'Short trades': short_trades_stats,\n",
    "        'Long trades': long_trades_stats\n",
    "    }, index=[\n",
    "        'Total number of round_trips',\n",
    "        'Percent profitable',\n",
    "        'Winning round_trips',\n",
    "        'Losing round_trips',\n",
    "    ])\n",
    "    \n",
    "    # Create PnL stats table\n",
    "    pnl_stats = pd.DataFrame({\n",
    "        'All trades': all_trades_stats,\n",
    "        'Short trades': short_trades_stats,\n",
    "        'Long trades': long_trades_stats\n",
    "    }, index=[\n",
    "        'Total profit',\n",
    "        'Gross profit',\n",
    "        'Gross loss',\n",
    "        'Profit factor',\n",
    "        'Avg. trade net profit',\n",
    "        'Avg. winning trade',\n",
    "        'Avg. losing trade',\n",
    "        'Ratio Avg. Win:Avg. Loss',\n",
    "        'Largest winning trade',\n",
    "        'Largest losing trade'\n",
    "    ])\n",
    "\n",
    "    # Updated Custom CSS for dark mode with improved padding\n",
    "    dark_mode_css = \"\"\"\n",
    "    <style>\n",
    "    .gt_table {\n",
    "        color: #ffffff;\n",
    "        background-color: #1e1e1e;\n",
    "        margin-left: 10px !important;\n",
    "        margin-right: auto !important;\n",
    "        width: auto !important;\n",
    "        padding-left: 10px !important;\n",
    "    }\n",
    "    .gt_heading {\n",
    "        background-color: #2a2a2a;\n",
    "        border-bottom-color: #444;\n",
    "    }\n",
    "    .gt_title {\n",
    "        color: #ffffff;\n",
    "        text-align: left !important;\n",
    "        padding-left: 10px !important;\n",
    "    }\n",
    "    .gt_subtitle {\n",
    "        color: #e0e0e0;\n",
    "        text-align: left !important;\n",
    "        padding-left: 10px !important;\n",
    "    }\n",
    "    .gt_column_spanner {\n",
    "        border-bottom-color: #444;\n",
    "        color: #ffffff;\n",
    "    }\n",
    "    .gt_row {\n",
    "        background-color: #1e1e1e;\n",
    "        color: #ffffff;\n",
    "        transition: background-color 0.3s;\n",
    "    }\n",
    "    .gt_row:hover {\n",
    "        background-color: #3a3a3a !important;\n",
    "    }\n",
    "    .gt_row:nth-child(even) {\n",
    "        background-color: #252525;\n",
    "    }\n",
    "    .gt_stub {\n",
    "        color: #ffffff;\n",
    "        background-color: #2a2a2a;\n",
    "        text-align: left !important;\n",
    "    }\n",
    "    .gt_summary_row {\n",
    "        background-color: #2a2a2a;\n",
    "        color: #ffffff;\n",
    "    }\n",
    "    .gt_grand_summary_row {\n",
    "        background-color: #333333;\n",
    "        color: #ffffff;\n",
    "    }\n",
    "    .gt_footnote {\n",
    "        color: #e0e0e0;\n",
    "        text-align: left !important;\n",
    "    }\n",
    "    .gt_source_notes {\n",
    "        background-color: #2a2a2a;\n",
    "        color: #e0e0e0;\n",
    "        text-align: left !important;\n",
    "    }\n",
    "    .gt_col_heading {\n",
    "        color: #ffffff;\n",
    "        text-align: left !important;\n",
    "    }\n",
    "    .gt_center {\n",
    "        text-align: left !important;\n",
    "    }\n",
    "    .gt_row td, .gt_stub, .gt_col_heading {\n",
    "        padding-left: 10px !important;\n",
    "    }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "    # Create and display Summary Stats table using great_tables\n",
    "    summary_gt = (\n",
    "        GT(summary_stats.reset_index())\n",
    "        .tab_header(title=\"Summary Statistics\")\n",
    "        .cols_label(\n",
    "            index=\"Metric\",\n",
    "            **{col: col.replace('_', ' ').title() for col in summary_stats.columns}\n",
    "        )\n",
    "        .opt_stylize(style=2, color=\"blue\")  # Apply a base style\n",
    "    )\n",
    "    \n",
    "    # Create and display PnL Stats table using great_tables\n",
    "    pnl_gt = (\n",
    "        GT(pnl_stats.reset_index())\n",
    "        .tab_header(title=\"Profit and Loss Statistics\")\n",
    "        .cols_label(\n",
    "            index=\"Metric\",\n",
    "            **{col: col.replace('_', ' ').title() for col in pnl_stats.columns}\n",
    "        )\n",
    "        .opt_stylize(style=2, color=\"blue\")  # Apply a base style\n",
    "    )\n",
    "\n",
    "    # Combine dark mode CSS with table HTML\n",
    "    summary_html = dark_mode_css + summary_gt.render(context=\"html\")\n",
    "    pnl_html = dark_mode_css + pnl_gt.render(context=\"html\")\n",
    "\n",
    "    display(HTML(summary_html))\n",
    "    display(HTML(pnl_html))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def create_random_portfolios_efficient(df_rebalanced, num_simulations=100):\n",
    "    n_stocks = df_rebalanced.shape[1]\n",
    "    random_rows = np.random.choice([-1, 1], size=(num_simulations, n_stocks))\n",
    "    random_portfolios = [df_rebalanced * random_row for random_row in random_rows]\n",
    "    return random_portfolios\n",
    "\n",
    "def calculate_single_cumulative_return(random_portfolio):\n",
    "    random_returns = random_portfolio.mean(axis=1)\n",
    "    return (1 + random_returns).cumprod()\n",
    "\n",
    "def calculate_random_cumulative_returns(random_portfolios):\n",
    "    random_cumulative_returns = [\n",
    "        calculate_single_cumulative_return(portfolio)\n",
    "        for portfolio in random_portfolios\n",
    "    ]\n",
    "    return random_cumulative_returns\n",
    "\n",
    "# Function to run a single iteration\n",
    "def run_single_iteration(asset_returns, num_simulations):\n",
    "    random_portfolios = create_random_portfolios_efficient(asset_returns, num_simulations)\n",
    "    random_cumulative_returns = calculate_random_cumulative_returns(random_portfolios)\n",
    "    return pd.DataFrame(random_cumulative_returns).T\n",
    "\n",
    "\n",
    "def construct_samples(asset_returns):\n",
    "    # Run the process 20 times and concatenate results\n",
    "    num_iterations = 10\n",
    "    num_simulations = 5\n",
    "    random_cumulative_returns_df = pd.DataFrame()\n",
    "    for r in range(num_iterations):\n",
    "        iteration_result = run_single_iteration(asset_returns, num_simulations)\n",
    "        random_cumulative_returns_df = pd.concat([random_cumulative_returns_df, iteration_result], axis=1)\n",
    "        # print(r)\n",
    "    \n",
    "    random_cumulative_returns_df.columns = list(range(len(random_cumulative_returns_df.columns)))\n",
    "    \n",
    "    # Calculate 99% confidence interval\n",
    "    lower_bound = random_cumulative_returns_df.quantile(0.01, axis=1)\n",
    "    upper_bound = random_cumulative_returns_df.quantile(0.99, axis=1)\n",
    "    \n",
    "    # Find the indices of the strategies at the 1st and 99th percentiles\n",
    "    final_returns = random_cumulative_returns_df.iloc[-1]\n",
    "    lower_1_index = final_returns.rank(pct=True).idxmin()\n",
    "    upper_99_index = final_returns.rank(pct=True).idxmax()\n",
    "    \n",
    "    # Extract the 1st and 99th percentile strategies\n",
    "    lower_1_strategy = random_cumulative_returns_df[lower_1_index]\n",
    "    upper_99_strategy = random_cumulative_returns_df[upper_99_index]\n",
    "    \n",
    "    # Create a dictionary with the results\n",
    "    confidence_interval_data = {\n",
    "        'lower_bound': lower_bound,\n",
    "        'upper_bound': upper_bound,\n",
    "        'lower_1_strategy': lower_1_strategy,\n",
    "        'upper_99_strategy': upper_99_strategy\n",
    "    }\n",
    "\n",
    "    return confidence_interval_data\n",
    "\n",
    "\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "\n",
    "def calculate_rolling_sharpe_ratio(returns, window=52, risk_free_rate=0):\n",
    "    excess_returns = returns - risk_free_rate\n",
    "    rolling_mean = excess_returns.rolling(window=window).mean()\n",
    "    rolling_std = excess_returns.rolling(window=window).std()\n",
    "    rolling_std = rolling_std.replace(0, np.nan)\n",
    "    sharpe = (rolling_mean / rolling_std) * np.sqrt(52)\n",
    "    return sharpe.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "def plot_cumulative_performance_with_sharpe_and_random(cumulative_returns, portfolio_returns, lower_5_strategy, upper_95_strategy):\n",
    "    # Calculate rolling Sharpe ratio\n",
    "    rolling_sharpe = calculate_rolling_sharpe_ratio(portfolio_returns)\n",
    "    average_sharpe = rolling_sharpe.mean()\n",
    "\n",
    "    # Create the plot\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "    # Plot the range between lower_5_strategy and upper_95_strategy\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=lower_5_strategy.index,\n",
    "            y=lower_5_strategy.values,\n",
    "            fill=None,\n",
    "            mode='lines',\n",
    "            line_color='rgba(255, 255, 255, 0)',\n",
    "            showlegend=False,\n",
    "            hoverinfo='skip'\n",
    "        ),\n",
    "        secondary_y=True\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=upper_95_strategy.index,\n",
    "            y=upper_95_strategy.values,\n",
    "            fill='tonexty',\n",
    "            mode='lines',\n",
    "            line_color='rgba(100, 150, 255, 0.5)',\n",
    "            fillcolor='rgba(50, 100, 200, 0.3)',\n",
    "            name='95% Confidence Interval',\n",
    "            hoverinfo='skip'\n",
    "        ),\n",
    "        secondary_y=True\n",
    "    )\n",
    "\n",
    "    # Plot lower_5_strategy and upper_95_strategy\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=lower_5_strategy.index,\n",
    "            y=lower_5_strategy.values,\n",
    "            mode='lines',\n",
    "            name='2.5th Percentile',\n",
    "            line=dict(color='#FFFFFF', width=1, dash='dash'),\n",
    "            hovertemplate='Date: %{x}<br>2.5th Percentile: $%{y:.2f}<extra></extra>'\n",
    "        ),\n",
    "        secondary_y=True\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=upper_95_strategy.index,\n",
    "            y=upper_95_strategy.values,\n",
    "            mode='lines',\n",
    "            name='97.5th Percentile',\n",
    "            line=dict(color='#FFFFFF', width=1, dash='dash'),\n",
    "            hovertemplate='Date: %{x}<br>97.5th Percentile: $%{y:.2f}<extra></extra>'\n",
    "        ),\n",
    "        secondary_y=True\n",
    "    )\n",
    "\n",
    "    # Plot main strategy\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=cumulative_returns.index,\n",
    "            y=cumulative_returns.values,\n",
    "            mode='lines',\n",
    "            name='Strategy Returns',\n",
    "            line=dict(color='#00FFFF', width=2),\n",
    "            hovertemplate='Date: %{x}<br>Cumulative Returns: $%{y:.2f}<extra></extra>'\n",
    "        ),\n",
    "        secondary_y=True\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=rolling_sharpe.index,\n",
    "            y=rolling_sharpe.values,\n",
    "            mode='lines',\n",
    "            name='Sharpe Ratio',\n",
    "            line=dict(color='#FF6B6B'),\n",
    "            hovertemplate='Date: %{x}<br>Rolling Sharpe Ratio: %{y:.2f}<extra></extra>'\n",
    "        ),\n",
    "        secondary_y=False\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=rolling_sharpe.index,\n",
    "            y=[average_sharpe] * len(rolling_sharpe),\n",
    "            mode='lines',\n",
    "            name='Average Sharpe',\n",
    "            line=dict(color='#FFD700', dash='dash', width=1),\n",
    "            hovertemplate='Date: %{x}<br>Average Sharpe Ratio: %{y:.2f}<extra></extra>'\n",
    "        ),\n",
    "        secondary_y=False\n",
    "    )\n",
    "\n",
    "    max_value = max(\n",
    "        cumulative_returns.max(),\n",
    "        upper_95_strategy.max(),\n",
    "        lower_5_strategy.max()\n",
    "    )\n",
    "\n",
    "    # Add some padding (e.g., 50%) to ensure nothing gets cut off\n",
    "    y_max = max_value * 1.5\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='Cumulative Performance and Rolling Sharpe Ratio of Long-Short Strategy',\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Sharpe Ratio',\n",
    "        yaxis2_title='Portfolio Value ($)',\n",
    "        template='plotly_dark',\n",
    "        legend=dict(x=0.01, y=1.1, orientation='h'),\n",
    "        hovermode=\"x unified\",\n",
    "        yaxis=dict(\n",
    "            showgrid=False,\n",
    "            zeroline=True,\n",
    "            zerolinecolor='#404040',\n",
    "            zerolinewidth=1\n",
    "        ),\n",
    "        yaxis2=dict(\n",
    "            showgrid=False,\n",
    "            zeroline=True,\n",
    "            zerolinecolor='#404040',\n",
    "            zerolinewidth=1\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_yaxes(tickformat=\".2f\", secondary_y=False, range=[rolling_sharpe.min()*1.1, rolling_sharpe.max()*1.1])\n",
    "    fig.update_yaxes(tickformat=\"$,.2f\", secondary_y=True)\n",
    "\n",
    "    return fig\n",
    "    \n",
    "def performance_plot(cumulative_returns, portfolio_returns, simulations):\n",
    "    # Now call the function with your data\n",
    "    return plot_cumulative_performance_with_sharpe_and_random(cumulative_returns, portfolio_returns, simulations[\"lower_1_strategy\"], simulations[\"upper_99_strategy\"])\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "# Assuming portfolio_returns is your weekly returns series\n",
    "\n",
    "def get_event_returns(returns, start_date, end_date):\n",
    "    event_returns = returns.loc[start_date:end_date]\n",
    "    cumulative_returns = (1 + event_returns).cumprod() - 1\n",
    "    return cumulative_returns\n",
    "\n",
    "def stress_plotting(portfolio_returns):\n",
    "    # Define stress event dates\n",
    "    stress_events = {\n",
    "        'Dotcom': ('2000-03-01', '2002-10-01'),\n",
    "        'Lehman': ('2008-09-01', '2008-10-31'),\n",
    "        '9/11': ('2001-09-11', '2001-10-11'),\n",
    "        'US downgrade/European Debt Crisis': ('2011-08-01', '2011-09-30'),\n",
    "        'Fukushima': ('2011-03-11', '2011-04-11'),\n",
    "        'US Housing': ('2007-08-01', '2008-03-31'),\n",
    "        'EZB IR Event': ('2012-07-01', '2012-09-30'),\n",
    "        'Aug07': ('2007-08-01', '2007-09-30'),\n",
    "        'Mar08': ('2008-03-01', '2008-04-30'),\n",
    "        'Sept08': ('2008-09-01', '2008-10-31'),\n",
    "        '2009Q1': ('2009-01-01', '2009-03-31'),\n",
    "        '2009Q2': ('2009-04-01', '2009-06-30'),\n",
    "        'Flash Crash': ('2010-05-01', '2010-06-30'),\n",
    "        'Apr14': ('2014-04-01', '2014-05-31'),\n",
    "        'Oct14': ('2014-10-01', '2014-11-30'),\n",
    "        'Fall2015': ('2015-08-01', '2015-10-31'),\n",
    "        'Low Volatility Bull Market': ('2017-01-01', '2017-12-31'),\n",
    "        'GFC Crash': ('2008-09-01', '2009-03-31'),\n",
    "        'Recovery': ('2009-03-01', '2013-05-31'),\n",
    "        'New Normal': ('2013-01-01', '2019-12-31'),\n",
    "        'Covid': ('2020-02-01', '2020-04-30')\n",
    "    }\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import plotly.graph_objs as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    import plotly.express as px\n",
    "    \n",
    "    # (Keep the existing code for get_event_returns and stress_events definition)\n",
    "    \n",
    "    # Calculate cumulative returns for each stress event\n",
    "    event_returns = {}\n",
    "    event_avg_returns = {}\n",
    "    for event, (start, end) in stress_events.items():\n",
    "        returns = get_event_returns(portfolio_returns, start, end)\n",
    "        event_returns[event] = returns\n",
    "        event_avg_returns[event] = returns.iloc[-1] / len(returns)\n",
    "    \n",
    "    # Create a color map for events\n",
    "    color_map = px.colors.qualitative.Plotly\n",
    "    \n",
    "    # Create the main figure with secondary y-axis\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "    \n",
    "    # Add traces for cumulative returns\n",
    "    for i, (event, returns) in enumerate(event_returns.items()):\n",
    "        color = color_map[i % len(color_map)]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=returns.index, y=returns.values, mode='lines', name=event,\n",
    "                       line=dict(color=color),\n",
    "                       hovertemplate=f\"{event}<br>Date: %{{x}}<br>Cumulative Return: %{{y:.2%}}<extra></extra>\",\n",
    "                       showlegend=False),  # Hide from legend\n",
    "            secondary_y=True  # Changed to secondary y-axis\n",
    "        )\n",
    "    \n",
    "    # Select events for average return lines (you can modify this list)\n",
    "    selected_events = ['Dotcom', 'Lehman', 'GFC Crash', 'Covid', 'Recovery', 'New Normal']\n",
    "    \n",
    "    # Find the overall date range\n",
    "    all_dates = [date for returns in event_returns.values() for date in returns.index]\n",
    "    start_date, end_date = min(all_dates), max(all_dates)\n",
    "    \n",
    "    # Add horizontal lines for average returns of selected events\n",
    "    for i, event in enumerate(selected_events):\n",
    "        avg_return = event_avg_returns[event]\n",
    "        color = color_map[list(event_returns.keys()).index(event) % len(color_map)]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=[start_date, end_date],\n",
    "                       y=[avg_return, avg_return],\n",
    "                       mode='lines',\n",
    "                       name=f'{event} Avg ({avg_return:.2%})',  # Added actual average return\n",
    "                       line=dict(dash='dash', color=color),\n",
    "                       hovertemplate=f\"{event} Avg Return: {avg_return:.2%}<extra></extra>\"),\n",
    "            secondary_y=False  # Changed to primary y-axis\n",
    "        )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title_text=\"Cumulative Returns During Stress Events with Average Returns\",\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"Average Returns (Selected Events)\",  # Swapped\n",
    "        yaxis2_title=\"Cumulative Returns\",  # Swapped\n",
    "        template=\"plotly_white\",\n",
    "        showlegend=True,\n",
    "        hovermode=\"closest\",\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"top\",\n",
    "            y=-0.3,\n",
    "            xanchor=\"center\",\n",
    "            x=0.5\n",
    "        ),\n",
    "        margin=dict(b=100),\n",
    "        # height=700\n",
    "    )\n",
    "    \n",
    "    # Update axes (swapped)\n",
    "    fig.update_yaxes(tickformat=\".2%\", secondary_y=True)\n",
    "    fig.update_yaxes(tickformat=\".2%\", secondary_y=False)\n",
    "    \n",
    "    # Show plot\n",
    "    # fig.show()\n",
    "\n",
    "    fig.update_layout(template=\"plotly_dark\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from scipy.stats import norm, median_abs_deviation\n",
    "\n",
    "# Assuming you have already loaded your asset_returns DataFrame\n",
    "\n",
    "\n",
    "def distribution_plot(asset_returns, portfolio_returns):\n",
    "    # Calculate portfolio returns (mean across all assets for each date)\n",
    "    portfolio_returns = asset_returns.mean(axis=1)\n",
    "    \n",
    "    # Remove any NaN values\n",
    "    portfolio_returns = portfolio_returns.dropna()\n",
    "    \n",
    "    # Calculate statistics for the plot\n",
    "    mean_return = portfolio_returns.mean()\n",
    "    std_dev = portfolio_returns.std()\n",
    "    mad = median_abs_deviation(portfolio_returns)\n",
    "    var_95 = np.percentile(portfolio_returns, 5)\n",
    "    cvar_95 = portfolio_returns[portfolio_returns <= var_95].mean()\n",
    "    evar_95 = -np.log(np.mean(np.exp(-portfolio_returns / 0.05))) * 0.05\n",
    "    worst_realization = portfolio_returns.min()\n",
    "    \n",
    "    # Create the histogram\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Calculate histogram data manually\n",
    "    hist, bin_edges = np.histogram(portfolio_returns, bins=100, density=True)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    \n",
    "    # Add histogram trace\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=bin_centers,\n",
    "        y=hist,\n",
    "        name='Portfolio Returns',\n",
    "        marker=dict(color='rgba(173, 216, 230, 0.7)'),\n",
    "        hoverinfo='x+y',\n",
    "        hovertemplate='Return: %{x:.2%}<br>Probability: %{y:.2%}<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    # Add normal distribution trace\n",
    "    x = np.linspace(portfolio_returns.min(), portfolio_returns.max(), 1000)\n",
    "    normal_dist = norm.pdf(x, mean_return, std_dev)\n",
    "    normal_dist_scaled = normal_dist * (hist.max() / normal_dist.max())  # Correct scaling\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x,\n",
    "        y=normal_dist_scaled,\n",
    "        mode='lines',\n",
    "        name=f'Normal: μ = {mean_return:.2%}, σ = {std_dev:.2%}',\n",
    "        line=dict(color='orange', dash='dash')\n",
    "    ))\n",
    "    \n",
    "    # Add vertical lines for statistics with hover information\n",
    "    statistic_lines = [\n",
    "        (f'Mean: {mean_return:.2%}', mean_return, 'blue', 2),\n",
    "        (f'Mean - Std. Dev.({std_dev:.2%}): {mean_return - std_dev:.2%}', mean_return - std_dev, 'red', 1),\n",
    "        (f'Mean - MAD({mad:.2%}): {mean_return - mad:.2%}', mean_return - mad, 'magenta', 1),\n",
    "        (f'95.00% Confidence VaR: {var_95:.2%}', var_95, 'green', 1),\n",
    "        (f'95.00% Confidence CVaR: {cvar_95:.2%}', cvar_95, 'cyan', 1),\n",
    "        (f'95.00% Confidence EVaR: {evar_95:.2%}', evar_95, 'orange', 1),\n",
    "        (f'Worst Realization: {worst_realization:.2%}', worst_realization, 'gray', 1)\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    for name, value, color, width in statistic_lines:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[value, value],\n",
    "            y=[0, hist.max()+5],\n",
    "            mode='lines',\n",
    "            name=name,\n",
    "            line=dict(color=color, width=width),\n",
    "            hoverinfo='name+x',\n",
    "            hovertemplate=f\"{name}: %{{x:.2%}}<extra></extra>\"\n",
    "        ))\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title='Portfolio Returns Histogram',\n",
    "        xaxis_title='Returns',\n",
    "        yaxis_title='Probability Density',\n",
    "        # height=600,\n",
    "        # width=1000,\n",
    "        template='plotly_dark',\n",
    "        xaxis=dict(tickformat='.2%', range=[-0.06, 0.06]),\n",
    "        yaxis=dict(range=[0, hist.max() * 1.1]),  # Adjust y-axis range\n",
    "        legend=dict(\n",
    "            x=1.1,\n",
    "            y=1.1,\n",
    "            xanchor='right',\n",
    "            yanchor='top',\n",
    "            # bgcolor='rgba(255, 255, 255, 0.7)',\n",
    "            bordercolor='rgba(0, 0, 0, 0.5)',\n",
    "            borderwidth=1\n",
    "        ),\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "\n",
    "    fig.update_layout(template=\"plotly_dark\")\n",
    "    \n",
    "    \n",
    "    # Show the plot\n",
    "    # fig.show()\n",
    "    return fig\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def drawdown_plot(portfolio_returns):\n",
    "    # Calculate cumulative returns\n",
    "    cumulative_returns = (1 + portfolio_returns).cumprod()\n",
    "    \n",
    "    # Calculate drawdowns\n",
    "    previous_peaks = cumulative_returns.cummax()\n",
    "    drawdowns = (cumulative_returns - previous_peaks) / previous_peaks\n",
    "    drawdowns = drawdowns.bfill()\n",
    "\n",
    "    def find_drawdown_periods(drawdowns):\n",
    "        periods = []\n",
    "        in_drawdown = False\n",
    "        start_date = None\n",
    "        for date, value in drawdowns.items():\n",
    "            if not in_drawdown and value < 0:\n",
    "                in_drawdown = True\n",
    "                start_date = date\n",
    "            elif in_drawdown and value == 0:\n",
    "                in_drawdown = False\n",
    "                periods.append((start_date, date, drawdowns[start_date:date].min()))\n",
    "    \n",
    "        if in_drawdown:\n",
    "            periods.append((start_date, drawdowns.index[-1], drawdowns[start_date:].min()))\n",
    "    \n",
    "        return sorted(periods, key=lambda x: x[2])[:5]\n",
    "    \n",
    "    top_5_drawdowns = find_drawdown_periods(drawdowns)\n",
    "    \n",
    "    fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.03, row_heights=[0.4, 0.6])\n",
    "    \n",
    "    # Add cumulative returns trace\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=cumulative_returns.index, y=cumulative_returns, name=\"Portfolio\",\n",
    "                   line=dict(color='#00FFFF', width=1), fill='tozeroy', fillcolor='rgba(0,255,255,0.1)'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Add drawdown trace\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=drawdowns.index, y=drawdowns, fill='tozeroy', name=\"Drawdown\",\n",
    "                   line=dict(color='#FF6B6B', width=1), fillcolor='rgba(255,107,107,0.3)'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Add top 5 drawdown periods\n",
    "    colors = ['rgba(255,200,200,0.2)', 'rgba(255,180,180,0.2)', 'rgba(255,160,160,0.2)',\n",
    "              'rgba(255,140,140,0.2)', 'rgba(255,120,120,0.2)']\n",
    "    \n",
    "    top_5_drawdowns.sort(key=lambda x: x[0])\n",
    "    \n",
    "    for i, ((start, end, depth), color) in enumerate(zip(top_5_drawdowns, colors)):\n",
    "        fig.add_vrect(\n",
    "            x0=start, x1=end,\n",
    "            fillcolor=color, opacity=0.5, layer=\"below\", line_width=0,\n",
    "            row='all'\n",
    "        )\n",
    "        y_position = cumulative_returns.max() * (0.8 - i * 0.15)\n",
    "        fig.add_annotation(\n",
    "            x=start + (end - start)/2, y=y_position,\n",
    "            text=f\"{depth:.2%}\",\n",
    "            showarrow=False,\n",
    "            font=dict(size=12, color=\"#FF6B6B\"),\n",
    "            row=1, col=1\n",
    "        )\n",
    "    \n",
    "    # Calculate drawdown statistics\n",
    "    def calculate_ulcer_index(drawdowns):\n",
    "        return np.sqrt(np.mean(drawdowns**2))\n",
    "    \n",
    "    def calculate_average_drawdown(drawdowns):\n",
    "        return drawdowns[drawdowns < 0].mean()\n",
    "    \n",
    "    def calculate_dar(drawdowns, confidence=0.95):\n",
    "        return np.percentile(drawdowns, (1 - confidence) * 100)\n",
    "    \n",
    "    def calculate_edar(drawdowns, confidence=0.95):\n",
    "        return calculate_dar(drawdowns, confidence) * 1.1\n",
    "    \n",
    "    ulcer_index = calculate_ulcer_index(drawdowns)\n",
    "    average_drawdown = calculate_average_drawdown(drawdowns)\n",
    "    dar_95 = calculate_dar(drawdowns, confidence=0.95)\n",
    "    edar_95 = calculate_edar(drawdowns, confidence=0.95)\n",
    "    max_drawdown = drawdowns.min()\n",
    "    \n",
    "    # Add horizontal lines for drawdown statistics\n",
    "    statistics = [\n",
    "        (\"Ulcer Index\", ulcer_index, '#00FFFF'),\n",
    "        (\"Average Drawdown\", average_drawdown, '#FF6B6B'),\n",
    "        (\"95.00% Confidence DaR\", dar_95, '#FF69B4'),\n",
    "        (\"95.00% Confidence EDaR\", edar_95, '#9370DB'),\n",
    "        (\"Maximum Drawdown\", max_drawdown, '#FFFFFF')\n",
    "    ]\n",
    "    \n",
    "    for name, value, color in statistics:\n",
    "        fig.add_shape(\n",
    "            type=\"line\",\n",
    "            x0=drawdowns.index[0],\n",
    "            x1=drawdowns.index[-1],\n",
    "            y0=value,\n",
    "            y1=value,\n",
    "            line=dict(color=color, width=1, dash=\"dash\"),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        fig.add_annotation(\n",
    "            x=drawdowns.index[-1],\n",
    "            y=value,\n",
    "            text=f\"{name}: {value:.2%}\",\n",
    "            showarrow=False,\n",
    "            xanchor=\"right\",\n",
    "            yanchor=\"bottom\",\n",
    "            font=dict(size=10, color=color),\n",
    "            row=2, col=1\n",
    "        )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title='Portfolio Performance and Drawdowns',\n",
    "        height=700,\n",
    "        legend_title_text='',\n",
    "        showlegend=True,\n",
    "        # plot_bgcolor='rgba(0,0,0,0)',\n",
    "        plot_bgcolor='black',\n",
    "        paper_bgcolor='black',\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1),\n",
    "        font=dict(color='#FFFFFF')\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Date\", row=2, col=1, showgrid=True, gridcolor='rgba(255,255,255,0.1)')\n",
    "    fig.update_yaxes(title_text=\"Cumulative<br>Returns\", row=1, col=1, showgrid=True, gridcolor='rgba(255,255,255,0.1)')\n",
    "    fig.update_yaxes(title_text=\"Drawdown\", tickformat='.0%', row=2, col=1, showgrid=True, gridcolor='rgba(255,255,255,0.1)')\n",
    "    \n",
    "    fig.update_yaxes(range=[min(drawdowns.min(), max_drawdown)*1.1, 0.01], row=2, col=1)\n",
    "\n",
    "    fig.update_layout(template=\"plotly_dark\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calculate_metrics(returns):\n",
    "    annual_return = (1 + returns).prod() ** (52 / len(returns)) - 1\n",
    "    metrics = {\n",
    "        'Annual return': annual_return,\n",
    "        'Cumulative returns': (1 + returns).prod() - 1,\n",
    "        'Annual volatility': returns.std() * np.sqrt(52),\n",
    "        'Sharpe ratio': annual_return / (returns.std() * np.sqrt(52)),\n",
    "        'Max drawdown': (returns.cummax() - returns).max(),\n",
    "        'Calmar ratio': annual_return / abs((returns.cummax() - returns).max()),\n",
    "        'Stability': 1 - (returns.std() / returns.mean()),\n",
    "        'Omega ratio': len(returns[returns > 0]) / len(returns[returns <= 0]),\n",
    "        'Sortino ratio': annual_return / (returns[returns < 0].std() * np.sqrt(52)),\n",
    "        'Skew': returns.skew(),\n",
    "        'Kurtosis': returns.kurtosis(),\n",
    "        'Tail ratio': abs(returns.quantile(0.95)) / abs(returns.quantile(0.05)),\n",
    "        'Weekly value at risk': returns.quantile(0.05),\n",
    "        'Gross leverage': 1.0,  # Assuming no leverage\n",
    "        'Weekly turnover': returns.abs().mean()\n",
    "    }\n",
    "    return pd.Series(metrics)\n",
    "\n",
    "def find_drawdown_periods(returns):\n",
    "    cum_returns = (1 + returns).cumprod()\n",
    "    drawdowns = cum_returns / cum_returns.cummax() - 1\n",
    "    drawdown_periods = []\n",
    "    in_drawdown = False\n",
    "    peak_date = valley_date = recovery_date = None\n",
    "\n",
    "    for date, value in drawdowns.items():\n",
    "        if not in_drawdown and value < 0:\n",
    "            in_drawdown, peak_date = True, date\n",
    "        elif in_drawdown and (valley_date is None or value < drawdowns[valley_date]):\n",
    "            valley_date = date\n",
    "        elif in_drawdown and value == 0:\n",
    "            recovery_date = date\n",
    "            drawdown_periods.append((peak_date, valley_date, recovery_date, drawdowns[peak_date:valley_date].min()))\n",
    "            in_drawdown, peak_date, valley_date, recovery_date = False, None, None, None\n",
    "\n",
    "    if in_drawdown:\n",
    "        drawdown_periods.append((peak_date, valley_date, 'Not Recovered', drawdowns[peak_date:valley_date].min()))\n",
    "\n",
    "    return sorted(drawdown_periods, key=lambda x: x[3])[:5]  # Sort by drawdown depth and get top 5\n",
    "\n",
    "def create_basic_info_table(start_date, end_date, out_of_sample_start):\n",
    "    return pd.DataFrame({\n",
    "        'Start date': [start_date],\n",
    "        'End date': [end_date],\n",
    "        'In-sample weeks': [(pd.to_datetime(out_of_sample_start) - pd.to_datetime(start_date)).days // 7],\n",
    "        'Out-of-sample weeks': [(pd.to_datetime(end_date) - pd.to_datetime(out_of_sample_start)).days // 7]\n",
    "    })\n",
    "\n",
    "def create_drawdown_table(worst_drawdowns):\n",
    "    return pd.DataFrame(\n",
    "        [(i, f\"{abs(depth):.2%}\",\n",
    "          peak_date.strftime('%Y-%m-%d') if peak_date else 'N/A',\n",
    "          valley_date.strftime('%Y-%m-%d') if valley_date else 'N/A',\n",
    "          recovery_date if recovery_date == 'Not Recovered' else (recovery_date.strftime('%Y-%m-%d') if recovery_date else 'N/A'),\n",
    "          (pd.to_datetime(recovery_date) - pd.to_datetime(peak_date)).days // 7 if recovery_date and recovery_date != 'Not Recovered' else 'NaN')\n",
    "         for i, (peak_date, valley_date, recovery_date, depth) in enumerate(worst_drawdowns)],\n",
    "        columns=['Index', 'Net drawdown in %', 'Peak date', 'Valley date', 'Recovery date', 'Duration (weeks)']\n",
    "    )\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from great_tables import GT, md, html\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Keep the existing helper functions (calculate_metrics, find_drawdown_periods, etc.) as they are\n",
    "\n",
    "def draw_down_statistics(portfolio_returns):\n",
    "    # Existing preprocessing code remains the same\n",
    "    portfolio_returns.index = pd.to_datetime(portfolio_returns.index)\n",
    "    portfolio_returns = portfolio_returns.sort_index()\n",
    "\n",
    "    start_date = portfolio_returns.index[0]\n",
    "    while start_date.weekday() != 4:\n",
    "        start_date += pd.Timedelta(days=1)\n",
    "\n",
    "    end_date = portfolio_returns.index[-1]\n",
    "    while end_date.weekday() != 4:\n",
    "        end_date -= pd.Timedelta(days=1)\n",
    "\n",
    "    out_of_sample_start = '2022-01-07'  # First Friday of 2022\n",
    "\n",
    "    in_sample_returns = portfolio_returns[start_date:out_of_sample_start]\n",
    "    out_of_sample_returns = portfolio_returns[out_of_sample_start:end_date]\n",
    "    all_returns = portfolio_returns[start_date:end_date]\n",
    "\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'In-sample': calculate_metrics(in_sample_returns),\n",
    "        'Out-of-sample': calculate_metrics(out_of_sample_returns),\n",
    "        'All': calculate_metrics(all_returns)\n",
    "    })\n",
    "\n",
    "    metrics_df = metrics_df.apply(lambda x: x.map('{:.3f}'.format))\n",
    "    metrics_df.loc['Gross leverage'] = '1.000'\n",
    "\n",
    "    # Updated Custom CSS for dark mode with improved padding\n",
    "    dark_mode_css = \"\"\"\n",
    "    <style>\n",
    "    .gt_table {\n",
    "        color: #ffffff;\n",
    "        background-color: #1e1e1e;\n",
    "        margin-left: 10px !important;\n",
    "        margin-right: auto !important;\n",
    "        width: auto !important;\n",
    "        padding-left: 10px !important;\n",
    "    }\n",
    "    .gt_heading {\n",
    "        background-color: #2a2a2a;\n",
    "        border-bottom-color: #444;\n",
    "    }\n",
    "    .gt_title {\n",
    "        color: #ffffff;\n",
    "        text-align: left !important;\n",
    "        padding-left: 10px !important;\n",
    "    }\n",
    "    .gt_subtitle {\n",
    "        color: #e0e0e0;\n",
    "        text-align: left !important;\n",
    "        padding-left: 10px !important;\n",
    "    }\n",
    "    .gt_column_spanner {\n",
    "        border-bottom-color: #444;\n",
    "        color: #ffffff;\n",
    "    }\n",
    "    .gt_row {\n",
    "        background-color: #1e1e1e;\n",
    "        color: #ffffff;\n",
    "        transition: background-color 0.3s;\n",
    "    }\n",
    "    .gt_row:hover {\n",
    "        background-color: #3a3a3a !important;\n",
    "    }\n",
    "    .gt_row:nth-child(even) {\n",
    "        background-color: #252525;\n",
    "    }\n",
    "    .gt_stub {\n",
    "        color: #ffffff;\n",
    "        background-color: #2a2a2a;\n",
    "        text-align: left !important;\n",
    "    }\n",
    "    .gt_summary_row {\n",
    "        background-color: #2a2a2a;\n",
    "        color: #ffffff;\n",
    "    }\n",
    "    .gt_grand_summary_row {\n",
    "        background-color: #333333;\n",
    "        color: #ffffff;\n",
    "    }\n",
    "    .gt_footnote {\n",
    "        color: #e0e0e0;\n",
    "        text-align: left !important;\n",
    "    }\n",
    "    .gt_source_notes {\n",
    "        background-color: #2a2a2a;\n",
    "        color: #e0e0e0;\n",
    "        text-align: left !important;\n",
    "    }\n",
    "    .gt_col_heading {\n",
    "        color: #ffffff;\n",
    "        text-align: left !important;\n",
    "    }\n",
    "    .gt_center {\n",
    "        text-align: left !important;\n",
    "    }\n",
    "    .gt_row td, .gt_stub, .gt_col_heading {\n",
    "        padding-left: 10px !important;\n",
    "    }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "    # Create Table 1: Basic Information\n",
    "    table1_info = create_basic_info_table(start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'), out_of_sample_start)\n",
    "    table1_gt = (\n",
    "        GT(table1_info)\n",
    "        .tab_header(title=\"Basic Information\")\n",
    "        .opt_stylize(style=2, color=\"blue\")\n",
    "    )\n",
    "\n",
    "    # Create Table 2: Performance Overview\n",
    "    table2_gt = (\n",
    "        GT(metrics_df.reset_index())\n",
    "        .tab_header(title=\"Performance Overview\")\n",
    "        .cols_label(\n",
    "            index=\"Metric\",\n",
    "            **{col: col for col in metrics_df.columns}\n",
    "        )\n",
    "        .opt_stylize(style=2, color=\"blue\")\n",
    "    )\n",
    "\n",
    "    # Create Table 3: Worst Drawdown Periods\n",
    "    worst_drawdowns = find_drawdown_periods(all_returns)\n",
    "    table3 = create_drawdown_table(worst_drawdowns)\n",
    "    table3_gt = (\n",
    "        GT(table3)\n",
    "        .tab_header(title=\"Worst Drawdown Periods\")\n",
    "        .opt_stylize(style=2, color=\"blue\")\n",
    "    )\n",
    "\n",
    "    # Combine dark mode CSS with table HTML\n",
    "    table1_html = dark_mode_css + table1_gt.render(context=\"html\")\n",
    "    table2_html = dark_mode_css + table2_gt.render(context=\"html\")\n",
    "    table3_html = dark_mode_css + table3_gt.render(context=\"html\")\n",
    "\n",
    "    # Display tables\n",
    "    display(HTML(table1_html))\n",
    "    display(HTML(table3_html))\n",
    "    display(HTML(table2_html))\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "def create_weekly_returns_heatmap(portfolio_returns):\n",
    "    # Ensure the index is datetime\n",
    "    portfolio_returns.index = pd.to_datetime(portfolio_returns.index)\n",
    "\n",
    "    # Get all unique years from the index\n",
    "    all_years = sorted(portfolio_returns.index.year.unique())\n",
    "\n",
    "    # Calculate monthly average of weekly returns\n",
    "    monthly_avg = portfolio_returns.groupby([portfolio_returns.index.year, portfolio_returns.index.month]).sum()\n",
    "\n",
    "    # Reshape the data into a 2D array, including all years\n",
    "    heatmap_data = monthly_avg.unstack(level=0).reindex(columns=all_years, fill_value=np.nan)\n",
    "\n",
    "    # Create a list of month names for y-axis labels\n",
    "    month_names = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "\n",
    "    # Get full year labels\n",
    "    year_labels = [str(year) for year in all_years]\n",
    "\n",
    "    # Create the heatmap\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=heatmap_data.values,\n",
    "        x=year_labels,\n",
    "        y=month_names,\n",
    "        colorscale='rdbu',  # Red for negative, Blue for positive\n",
    "        zmin=np.nanpercentile(heatmap_data.values, 5),  # 5th percentile for lower bound\n",
    "        zmax=np.nanpercentile(heatmap_data.values, 95),  # 95th percentile for upper bound\n",
    "        showscale=False,  # Remove the color scale\n",
    "        hovertemplate='Year: %{x}<br>Month: %{y}<br>Return: %{z:.2%}<extra></extra>',\n",
    "        text=heatmap_data.values,\n",
    "        texttemplate='%{text:.2%}',\n",
    "        textfont={\"size\": 10},\n",
    "    ))\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': 'Monthly Average Signal Returns',\n",
    "            'y':0.95,\n",
    "            'x':0.5,\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top',\n",
    "            'font': dict(size=18)\n",
    "        },\n",
    "        xaxis_title='Year',\n",
    "        yaxis_title='Month',\n",
    "        xaxis_tickangle=-90,\n",
    "        xaxis=dict(\n",
    "            tickmode='array',\n",
    "            tickvals=list(range(len(year_labels))),\n",
    "            ticktext=year_labels,\n",
    "            tickfont=dict(size=12)\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            tickfont=dict(size=12)\n",
    "        ),\n",
    "        font=dict(family=\"Arial\", size=14),\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "    )\n",
    "\n",
    "    # Add a border to the heatmap cells\n",
    "    fig.update_traces(xgap=1, ygap=1)\n",
    "\n",
    "    fig.update_layout(template=\"plotly_dark\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "def calculate_turnover(df, mask):\n",
    "    df_rebalance = df[mask]\n",
    "    # Separate long and short positions\n",
    "    long_positions = df_rebalance.where(df_rebalance > 0, 0)\n",
    "    short_positions = df_rebalance.where(df_rebalance < 0, 0).abs()\n",
    "    # Calculate changes for each strategy\n",
    "    long_changes = long_positions.diff().abs().sum(axis=1)\n",
    "    short_changes = short_positions.diff().abs().sum(axis=1)\n",
    "    # Calculate total turnover\n",
    "    total_turnover = long_changes + short_changes\n",
    "    # Calculate percentages\n",
    "    long_percentage = (long_changes / total_turnover * 100).fillna(0)\n",
    "    short_percentage = (short_changes / total_turnover * 100).fillna(0)\n",
    "    return pd.DataFrame({\n",
    "        'Long Turnover %': long_percentage,\n",
    "        'Short Turnover %': -short_percentage  # Negative to show below x-axis\n",
    "    })\n",
    "\n",
    "\n",
    "def turnover_plot(df_balance, rebalance_mask):\n",
    "    # Calculate turnover percentages\n",
    "    turnover_df = calculate_turnover(df_balance, rebalance_mask) \n",
    "    turnover_df = turnover_df.query(\"index >= '1999-01-01'\")\n",
    "    \n",
    "    # Find the max and min values\n",
    "    y_max = max(turnover_df['Long Turnover %'].max(), abs(turnover_df['Short Turnover %'].min()))\n",
    "    y_min = -y_max  # Make it symmetrical\n",
    "    \n",
    "    # Create the stacked bar chart\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=turnover_df.index,\n",
    "        y=turnover_df['Long Turnover %'],\n",
    "        name='Long Turnover',\n",
    "        marker_color='rgba(0, 123, 255, 0.7)'\n",
    "    ))\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=turnover_df.index,\n",
    "        y=turnover_df['Short Turnover %'],\n",
    "        name='Short Turnover',\n",
    "        marker_color='rgba(255, 99, 132, 0.7)'\n",
    "    ))\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': 'Portfolio Turnover Percentage (4-Week Rebalancing)',\n",
    "            'y':0.95,\n",
    "            'x':0.5,\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top',\n",
    "            'font': dict(size=24)\n",
    "        },\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Turnover Percentage',\n",
    "        barmode='relative',\n",
    "        legend_title='Position Type',\n",
    "        hovermode='x unified',\n",
    "        plot_bgcolor='black',\n",
    "        # width=1200,\n",
    "        height=600,\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.02,\n",
    "            xanchor=\"right\",\n",
    "            x=1\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Adjust x-axis\n",
    "    fig.update_xaxes(\n",
    "        tickformat='%Y-%m',\n",
    "        dtick='M6',\n",
    "        tickangle=45,\n",
    "        showgrid=True,\n",
    "        gridcolor='lightgrey'\n",
    "    )\n",
    "    \n",
    "    # Adjust y-axis\n",
    "    fig.update_yaxes(\n",
    "        range=[y_min, y_max],  # Set the range based on data\n",
    "        ticksuffix='%',\n",
    "        showgrid=True,\n",
    "        gridcolor='lightgrey',\n",
    "        zeroline=True,\n",
    "        zerolinecolor='black',\n",
    "        zerolinewidth=2\n",
    "    )\n",
    "    \n",
    "    # Show the plot\n",
    "\n",
    "    fig.update_layout(template=\"plotly_dark\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def fast_rolling_autocorrelation(df, window):\n",
    "    # Convert DataFrame to NumPy array\n",
    "    data = df.values\n",
    "\n",
    "    # Create 3D array: (window, num_rows - window + 1, num_columns)\n",
    "    shape = (window, data.shape[0] - window + 1, data.shape[1])\n",
    "    strides = (data.strides[0], data.strides[0], data.strides[1])\n",
    "    windows = np.lib.stride_tricks.as_strided(data, shape=shape, strides=strides)\n",
    "\n",
    "    # Calculate means for each window\n",
    "    means = np.mean(windows, axis=0)\n",
    "\n",
    "    # Calculate variances for each window\n",
    "    variances = np.var(windows, axis=0)\n",
    "\n",
    "    # Calculate covariance\n",
    "    covariance = np.mean((windows[:-1] - means) * (windows[1:] - means), axis=0)\n",
    "\n",
    "    # Calculate autocorrelation\n",
    "    autocorrelation = covariance / variances\n",
    "\n",
    "    # Create DataFrame with results\n",
    "    result = pd.DataFrame(autocorrelation, index=df.index[window-1:], columns=df.columns)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def signal_correlation(df_signal):\n",
    "    window_size = 12\n",
    "    autocorrelation = fast_rolling_autocorrelation(df_signal, window_size)\n",
    "    autocorrelation_single = autocorrelation.query(\"date >='1999-01-01'\").mean(axis=1)\n",
    "    \n",
    "    mean_autocorrelation = np.mean(autocorrelation_single)\n",
    "    \n",
    "    fig = make_subplots(rows=1, cols=1)\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=autocorrelation_single.index,\n",
    "            y=autocorrelation_single.values,\n",
    "            mode='lines',\n",
    "            name='Autocorrelation'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.add_hline(y=mean_autocorrelation, line_dash=\"dash\", line_color=\"red\",\n",
    "                  annotation_text=f\"Mean: {mean_autocorrelation:.3f}\", \n",
    "                  annotation_position=\"top right\")\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Signal Rank Autocorrelation Over Time',\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Autocorrelation',\n",
    "        hovermode='x unified',\n",
    "        # template='plotly_white'  # This will adapt to dark mode automatically\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def create_portfolio_holdings_fast(df_signal, lower_bound, upper_bound):\n",
    "    signal_array = df_signal.values\n",
    "    holdings_array = np.zeros_like(signal_array)\n",
    "    holdings_array[(signal_array > lower_bound) & (signal_array <= upper_bound)] = 1\n",
    "    holdings_array[np.isnan(signal_array)] = np.nan\n",
    "    df_holdings = pd.DataFrame(holdings_array, index=df_signal.index, columns=df_signal.columns)\n",
    "    return df_holdings\n",
    "\n",
    "def calculate_returns_and_sharpe(df_holdings, df_prices, risk_free_rate=0):\n",
    "    df_temp = df_holdings.fillna(2)\n",
    "    rebalance_mask = pd.Series(False, index=df_temp.index)\n",
    "    rebalance_mask.iloc[0] = True\n",
    "    rebalance_mask.iloc[4::4] = True\n",
    "    df_rebalanced = df_temp.where(rebalance_mask, np.nan).ffill().replace({2: np.nan, 0: np.nan})\n",
    "\n",
    "    price_changes = df_prices.pct_change(fill_method=None).clip(upper=1)\n",
    "    asset_returns = df_rebalanced * price_changes\n",
    "    portfolio_returns = asset_returns.mean(axis=1)\n",
    "    cumulative_returns = (1 + portfolio_returns).cumprod()\n",
    "\n",
    "    excess_returns = portfolio_returns - risk_free_rate\n",
    "    sharpe_ratio = np.sqrt(52) * excess_returns.mean() / excess_returns.std()\n",
    "\n",
    "    return cumulative_returns, sharpe_ratio\n",
    "\n",
    "\n",
    "def process_decile(i, df_signal, df_prices):\n",
    "    lower_bound = i * 10\n",
    "    upper_bound = (i + 1) * 10\n",
    "    df_holdings = create_portfolio_holdings_fast(df_signal, lower_bound, upper_bound)\n",
    "    returns, sharpe = calculate_returns_and_sharpe(df_holdings, df_prices)\n",
    "    return f'Decile {i+1}', returns, sharpe\n",
    "\n",
    "\n",
    "def decile_plots(df_signal, df_prices):\n",
    "    # Assuming df_signal and df_prices are already defined\n",
    "    \n",
    "    # Use joblib to parallelize the calculations\n",
    "    results = Parallel(n_jobs=-1)(delayed(process_decile)(i, df_signal, df_prices) for i in range(10))\n",
    "    \n",
    "    # Convert results to dictionaries\n",
    "    decile_returns = {decile: returns for decile, returns, _ in results}\n",
    "    decile_sharpes = {decile: sharpe for decile, _, sharpe in results}\n",
    "    \n",
    "    # Create the plot with secondary y-axis\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "    \n",
    "    # Plot cumulative returns\n",
    "    for decile, returns in decile_returns.items():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=returns.index,\n",
    "            y=returns.values,\n",
    "            mode='lines',\n",
    "            name=decile\n",
    "        ), secondary_y=True)\n",
    "    \n",
    "    # Add horizontal lines for average Sharpe ratios on secondary y-axis\n",
    "    for decile, sharpe in decile_sharpes.items():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[returns.index[0], returns.index[-1]],\n",
    "            y=[sharpe, sharpe],\n",
    "            mode='lines',\n",
    "            name=f'{decile} Sharpe: {sharpe:.2f}',\n",
    "            line=dict(dash='dash'),\n",
    "            showlegend=False\n",
    "        ), secondary_y=False)\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title='Signal Cumulative Returns by Decile with Average Sharpe Ratios',\n",
    "        xaxis_title='Date',\n",
    "        # template='plotly_white',\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.02,\n",
    "            xanchor=\"right\",\n",
    "            x=1\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Update y-axes\n",
    "    fig.update_yaxes(title_text=\"Cumulative Returns\", secondary_y=True)\n",
    "    fig.update_yaxes(title_text=\"Sharpe Ratio\", secondary_y=False)\n",
    "\n",
    "    fig.update_layout(template=\"plotly_dark\", height=500,)\n",
    "    \n",
    "    # Show the plot\n",
    "    return fig\n",
    "    \n",
    "    # If you want to save the plot as an HTML file\n",
    "    # fig.write_html(\"cumulative_returns_and_sharpe_by_decile.html\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import norm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "class SignalEvaluator:\n",
    "    def __init__(self, df_factor):\n",
    "\n",
    "        self.df_factor = df_factor\n",
    "        self.df_signal, self.df_prices = self._signal_frame() \n",
    "        self.positions = self._create_portfolio_holdings()\n",
    "        self.rebalance_mask = self._calc_rebalanced_mask()\n",
    "        self.holdings = self._real_holdings()\n",
    "        self.returns = self._calculate_returns()\n",
    "        self.position_returns = self._calculate_position_returns()\n",
    "        self.resampled_returns = self._calculate_resampled_returns()\n",
    "        self.portfolio_returns = self._portfolio_returns()\n",
    "        self.cumulative_returns = self._cummulative_returns()\n",
    "        \n",
    "        # self.statistics = self._calculate_statistics()\n",
    "\n",
    "    def _signal_frame(self):\n",
    "        factor = self.df_factor\n",
    "        column_name = factor.columns[0]\n",
    "        df_factor = factor.add_price()\n",
    "        \n",
    "        df_signal = df_factor[column_name].unstack(level='ticker').shift(1)\n",
    "        \n",
    "        # Create wide DataFrame for prices\n",
    "        df_prices = df_business_risk['price'].unstack(level='ticker')\n",
    "\n",
    "        return df_signal, df_prices\n",
    "\n",
    "    def _create_portfolio_holdings(self):\n",
    "        signal_array = self.df_signal.values\n",
    "        holdings_array = np.zeros_like(signal_array)\n",
    "        holdings_array[signal_array <= 10] = -1\n",
    "        holdings_array[signal_array >= 90] = 1\n",
    "        holdings_array[np.isnan(signal_array)] = np.nan\n",
    "        return pd.DataFrame(holdings_array, index=self.df_signal.index, columns=self.df_signal.columns)\n",
    "\n",
    "    def _calc_rebalanced_mask(self):\n",
    "        # Create the portfolio holdings DataFrame\n",
    "        df_holdings = self.positions \n",
    "        \n",
    "        # Replace NaNs with 2 (our temporary placeholder)\n",
    "        df_temp = df_holdings.fillna(2)\n",
    "        \n",
    "        # Create a 4-weekly rebalancing mask\n",
    "        rebalance_mask = pd.Series(False, index=df_temp.index)\n",
    "        rebalance_mask.iloc[0] = True  # Always include the first row\n",
    "        rebalance_mask.iloc[4::4] = True  # Then every 4th row\n",
    "        return rebalance_mask\n",
    "\n",
    "    \n",
    "    def _real_holdings(self):\n",
    "        # Create the portfolio holdings DataFrame\n",
    "        df_holdings = self.positions \n",
    "        \n",
    "        # Replace NaNs with 2 (our temporary placeholder)\n",
    "        df_temp = df_holdings.fillna(2)\n",
    "        \n",
    "        rebalance_mask = self.rebalance_mask \n",
    "        \n",
    "        # Apply the rebalancing mask\n",
    "        df_balance = df_temp.where(rebalance_mask, np.nan)\n",
    "        \n",
    "        # Forward fill\n",
    "        df_balance = df_balance.ffill()\n",
    "        \n",
    "        # Replace 2 with NaN to restore original NaN structure\n",
    "        df_balance = df_balance.replace(2, np.nan)\n",
    "        \n",
    "        df_balance = df_balance.replace(0, np.nan)\n",
    "\n",
    "        return df_balance\n",
    "    \n",
    "    def _portfolio_returns(self):\n",
    "            # Calculate portfolio returns (sum across all assets for each date)\n",
    "        portfolio_returns = self.position_returns.mean(axis=1)\n",
    "\n",
    "        return portfolio_returns\n",
    "        \n",
    "    def _cummulative_returns(self):\n",
    "            # Calculate portfolio returns (sum across all assets for each date)\n",
    "   \n",
    "        # Calculate cumulative returns\n",
    "        cumulative_returns = (1 + self.portfolio_returns).cumprod()\n",
    "\n",
    "        return cumulative_returns\n",
    "        \n",
    "    def _calculate_returns(self):\n",
    "        return self.df_prices.pct_change(fill_method=None).clip(upper=3)\n",
    "\n",
    "    def _calculate_position_returns(self):\n",
    "        return self.holdings * self.returns\n",
    "\n",
    "    def _calculate_resampled_returns(self):\n",
    "        rebalance_mask = pd.Series(False, index=self.position_returns.index)\n",
    "        rebalance_mask.iloc[0] = True\n",
    "        rebalance_mask.iloc[4::4] = True\n",
    "        \n",
    "        def custom_resampler(x):\n",
    "            return x.sum()\n",
    "        \n",
    "        group_numbers = (rebalance_mask.cumsum() - 1).ffill()\n",
    "        resampled_returns = self.position_returns.groupby(group_numbers).apply(custom_resampler)\n",
    "        resampled_returns.index = rebalance_mask[rebalance_mask==True].index\n",
    "        return resampled_returns\n",
    "\n",
    "    def _calculate_statistics(self):\n",
    "        return draw_down_statistics(self.position_returns.mean(axis=1))\n",
    "\n",
    "    @property\n",
    "    def performance_plot(self):\n",
    "        return performance_plot(self.cumulative_returns, self.portfolio_returns, self._construct_samples())\n",
    "\n",
    "    @property\n",
    "    def performance_table(self):\n",
    "        return statistics(self.resampled_returns, self.holdings[self.rebalance_mask])\n",
    "\n",
    "    @property\n",
    "    def stress_plot(self):\n",
    "        return stress_plotting(self.position_returns.mean(axis=1))\n",
    "\n",
    "    @property\n",
    "    def distribution_plot(self):\n",
    "        return distribution_plot(self.position_returns, self.position_returns.mean(axis=1))\n",
    "\n",
    "    @property\n",
    "    def drawdown_plot(self):\n",
    "        return drawdown_plot(self.position_returns.mean(axis=1))\n",
    "\n",
    "    @property\n",
    "    def drawdown_table(self):\n",
    "        return draw_down_statistics(self.position_returns.mean(axis=1))\n",
    "\n",
    "    @property\n",
    "    def returns_heatmap_plot(self):\n",
    "        return create_weekly_returns_heatmap(self.position_returns.mean(axis=1))\n",
    "\n",
    "    @property\n",
    "    def turnover_plot(self):\n",
    "        rebalance_mask = pd.Series(False, index=self.positions.index)\n",
    "        rebalance_mask.iloc[0] = True\n",
    "        rebalance_mask.iloc[4::4] = True\n",
    "        return turnover_plot(self.positions, rebalance_mask)\n",
    "\n",
    "    @property\n",
    "    def signal_correlation_plot(self):\n",
    "        return signal_correlation(self.df_signal)\n",
    "\n",
    "    @property\n",
    "    def signal_decile_plot(self):\n",
    "        return decile_plots(self.df_signal, self.df_prices)\n",
    "\n",
    "    def _construct_samples(self):\n",
    "        return construct_samples(self.position_returns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4652e61b-3e71-472d-8357-054578cad331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and saving new file.\n"
     ]
    }
   ],
   "source": [
    "import sovai as sov\n",
    " \n",
    "sov.token_auth(token=\"your_token_here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ada98a95-7bfa-4bfa-9a28-31cf6ecada53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>business_risk</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">A</th>\n",
       "      <th>1999-11-26</th>\n",
       "      <td>26.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-12-03</th>\n",
       "      <td>26.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-12-10</th>\n",
       "      <td>26.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-12-17</th>\n",
       "      <td>26.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-12-24</th>\n",
       "      <td>26.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ZZ</th>\n",
       "      <th>2013-02-15</th>\n",
       "      <td>55.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-22</th>\n",
       "      <td>44.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-01</th>\n",
       "      <td>43.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-08</th>\n",
       "      <td>44.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-15</th>\n",
       "      <td>45.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9062256 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   business_risk\n",
       "ticker date                     \n",
       "A      1999-11-26         26.000\n",
       "       1999-12-03         26.000\n",
       "       1999-12-10         26.000\n",
       "       1999-12-17         26.000\n",
       "       1999-12-24         26.000\n",
       "...                          ...\n",
       "ZZ     2013-02-15         55.000\n",
       "       2013-02-22         44.000\n",
       "       2013-03-01         43.000\n",
       "       2013-03-08         44.000\n",
       "       2013-03-15         45.000\n",
       "\n",
       "[9062256 rows x 1 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comprehensive = sov.data(\"factors/comprehensive\")\n",
    "\n",
    "df_risk = df_comprehensive[[\"business_risk\"]]; del df_comprehensive; df_risk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b49e79ea-f20a-4f94-a1fd-b707dd22259f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CustomDataFrame' object has no attribute 'signal_evaluator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tj/2qbc2n2x1234_l7b3z5y06740000gn/T/ipykernel_17049/1060298832.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_risk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal_evaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Sovai/GitHub/SovAI/.venv/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5898\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5899\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5900\u001b[0m         ):\n\u001b[1;32m   5901\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5902\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'CustomDataFrame' object has no attribute 'signal_evaluator'"
     ]
    }
   ],
   "source": [
    "evaluator = df_risk.signal_evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d1852d40-7ac4-4aa0-bd03-b4347a4a779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_signal and df_prices are your input DataFrames\n",
    "evaluator = SignalEvaluator(df_risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2be142a-2d37-4073-bd2f-3ac138a68b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.performance_plot\n",
    "\n",
    "evaluator.signal_decile_plot\n",
    "\n",
    "evaluator.stress_plot\n",
    "\n",
    "evaluator.drawdown_plot\n",
    "\n",
    "evaluator.distribution_plot\n",
    "\n",
    "evaluator.returns_heatmap_plot\n",
    "\n",
    "evaluator.signal_correlation_plot\n",
    "\n",
    "evaluator.turnover_plot\n",
    "\n",
    "evaluator.performance_table\n",
    "\n",
    "evaluator.drawdown_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
