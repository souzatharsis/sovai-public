{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sovai as sov\n",
    "\n",
    "sov.token_auth(token=\"your_token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ratios - takes around 5 mins to load data \n",
    "df_accounting = sov.data(\"accounting/weekly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose long enough history for the model to train\n",
    "df_mega = df_accounting.select_stocks(\"mega\").date_range(\"2018-01-01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panel Clustering\n",
    "\n",
    "This clustering methodology takes multivariate panel datasets and represents them according to the centroids that capture the main patterns within the time series data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Features\n",
    "First think we can do is to calculate the clusters according to all the features as compared accross all the tickers in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = df_mega.cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specific Features\n",
    "We can also focus on any specific feature in the dataset of tens of features like `total_debt`, `total_assets`, or as we are using below `ebit`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_ebit = df_mega.cluster(features=[\"ebit\"]); df_cluster_ebit.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also specify our own selection of multiple features like ``features=[\"total_assets\",\"total_debt\",\"ebit\"]``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mega.cluster(features=[\"total_assets\",\"total_debt\",\"ebit\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downstream Calculations\n",
    "There are many things you can do once the data is clustered in time series, for one, you can take the standard deviation of the standard deviation of similarity accross clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def transform_df(merged_df):\n",
    "    # Reset the index to have 'ticker' and 'date' as columns\n",
    "    df_reset = merged_df.reset_index()\n",
    "\n",
    "    # Identify the numerical columns (assuming they start with 'Centroid')\n",
    "    centroid_columns = [col for col in df_reset.columns if col.startswith('Centroid') and col != 'Centroid labels']\n",
    "\n",
    "    # Calculate the average of the centroid columns\n",
    "    df_reset['average'] = df_reset[centroid_columns].std(axis=1)\n",
    "\n",
    "    # Pivot the table to have dates as index and tickers as columns\n",
    "    transformed_df = df_reset.pivot(index='date', columns='ticker', values='average')\n",
    "\n",
    "    return transformed_df\n",
    "\n",
    "# Use the function\n",
    "transformed_df = transform_df(df_cluster)\n",
    "max_date = transformed_df.index.max()\n",
    "sorted_df = (transformed_df.query(\"date == @max_date\")\n",
    "                           .T\n",
    "                           .reset_index()\n",
    "                           .sort_values(by=max_date, ascending=False)\n",
    "                           .reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Companies who are stable and stay within their accounting cluster over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.std().sort_values(ascending=False).tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Companies who are see-sawing through accounting clusters over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.std().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance Cluster\n",
    "\n",
    "We can use our in-built distance functionality to get the distances between the ticker-cluster combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dist = df_cluster.drop(columns=[\"labels\"]).distance(orient=\"time-series\"); df_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance calculation for companies with similar clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dist.sort_values([\"AMZN\"])[[\"AMZN\"]].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about ebit clustering distance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_ebit.drop(columns=[\"labels\"]).distance(orient=\"time-series\").sort_values([\"AMZN\"])[[\"AMZN\"]].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "This gives you a quick summary of the last 6-months data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mega.cluster(\"summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vizualisation\n",
    "Each colored line represents a distance to centroid of the cluster. The centroid is the average pattern of all time series assigned to that cluster. These are similarity scores (based on cross-correlation). Selecting features shows you the different shapes over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mega.cluster(\"line_plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mega.cluster(\"scatter_plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mega.cluster(\"animation_plot\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "b7bc88ef2312de8ccb6fe32ee45ed1b303064bae6342b11333199520ddc77aae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
